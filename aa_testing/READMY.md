Отдельно хочется рассказать про такую большую тему, как АА-тесты.



### Что такое А/А-тесты

_А/А-тесты_ – это вариация А/B-теста. Результаты A/B-тестирования помогают понять, какое решение даст большую конверсию в нужное целевое действие.

Суть данного метода заключается в том, что происходит сравнение двух разных версий страницы: первая показывается одной группе пользователей, а вторая – другой (распределение посетителей между двумя вариантами контента происходит случайным образом). После чего оцениваются результаты: в каком случае больше посетителей перешли по ссылке, зарегистрировались на сайте либо в приложении, подписались на рассылку или заполнили форму обратной связи.

Поведение клиентов анализируется посредством различных KPI: коэффициента кликабельности (CTR), коэффициента конверсии (CR) или дохода (revenue). Таким образом можно выяснить, какое предложение лучше привлекает целевую аудиторию, приносит наибольшую конверсию и приводит больше клиентов, а на основе этого принимается решение, какую вариацию следует использовать в дальнейшем. 
Несмотря на популярность метода A/B-тестирования, достаточно высокий процент результатов этих тестов не подтверждаются на практике. После внесения изменений конверсия может понизиться, из-за чего компания рискует потерять время и деньги.

Для решения данной проблемы и были разработаны A/A-тесты, где оба варианта для сравнения идентичны, и цель их – проверка точности и результата А/B-теста, который после будет запущен в тех же условиях, но с различными вариантами страницы. Когда можно увидеть, что происходит при сравнении одинаковых вариантов, можно более адекватно оценивать различия при сравнении двух разных версий.

### Тестирования в маркетинге

Поскольку оба варианта, участвующие в тестировании, идентичны, предполагается, что серьезных различий в результатах эксперимента наблюдаться не может. Разница между показателями конверсии на обеих страницах не должна выходить за пределы статистической погрешности. Если по результатам проведения A/A-тестирования выяснилось, что один вариант лучше другого, таким результатам доверять нельзя. Стоит проверить настройки сервиса для проведения теста и однородность выборки, возможно, аудитория распределилась между страницами неравномерно. Для каждой вариации структура аудитории по полу, устройствам и географии должна быть приблизительно одинаковой.

Если A/A-тест не выявил победителя, и конверсия двух страниц совпадает, можно запускать A/B-тест. Таким образом, можно сказать, что эти типы тестов дополняют друг друга.

### Зачем нужно проводить А/А-тест

При помощи этого метода анализа можно проверить, что платформа для тестирования работает правильно. В случае, если сервис работает некорректно, A/A-тест покажет победителя. То же самое произойдет при неверно заданных настройках.

Также такой эксперимент позволяет определить базовый уровень конверсии. При помощи A/A-тестирования можно выявить интервал, в пределах которого измерения конверсии могут считаться случайными, не связанными с наличием изменений на странице.

Кроме того, A/A-тест дает возможность оценить минимальный объем выборки, а также время проведения тестирования для страницы. Если разница между показателями конверсии велика, возможно, стоит подождать еще несколько дней и накопить больше данных. Если показатели сравняются, значит, столько же времени потребуется для проведения и A/B-тестирования.

### Как провести A/A-тест

Для начала нужно выбрать платформу для проведения эксперимента – это должен быть тот же сервис, в котором будет запускаться A/B-тест.

На втором этапе нужно заняться настройкой теста и указать для сравнения одну и ту же страницу.

На третьем этапе происходит отслеживание результатов эксперимента. Не нужно беспокоиться, что вначале данные могут существенно отличаться. Показатели начнут выравниваться по мере роста количества участников тестирования. Не стоит торопиться с завершением теста – чем больше времени проводится эксперимент, тем точнее будет результат.

Если по результатам A/A-теста разница между вариантами не видна или минимальна, можете с уверенностью запускать A/B-тестирование, так как завершенный эксперимент показал, что вы сможете полагаться на его результаты.

### В чем минусы метода А/А-теста

На подобный эксперимент тратится много времени.

На старте проекта такой тест практически бесполезен. Чтобы сделать сайт более понятным для посетителей, лучше соберать обратную связь от целевой аудитории.

К сожалению, A/A-тест не может гарантировать результат. При его проведении не исключено возникновение проблем, которые негативно скажутся на точности эксперимента.








































Какие виды А/А-тестов существуют?

### A/A — 50% распределение

Самая распространенная установка параметров теста - 50/50, исходный вариант лендинга тестируется «сам против себя». Для чего?

В данном случае идея теста заключается в подтверждении правильности (валидации) предварительных настроек. При показе одного и того же варианта лендинга двум контрольным группам пользователей в течение достаточного длительного периода времени можно получить примерно одинаковые значения конверсии от каждой группы.

Таким образом определяется соотношение «сигнал/шум» (полезные/бесполезные данные) в массиве получаемой информации. Если обратиться к известному примеру с подбрасыванием монетки («орел или решка»), монетку необходимо подбрасывать ее до тех пор, пока количество выпавших «орлов» не сравнится с числом выпавших «решек».

Проблема в том, что это действие занимает время, которое, как правило, используется для полноценного сплит-теста. Если у вас большой трафик, вы можете применить А/А-тесты, если вам так угодно, но разумнее будет перед запуском сплит-тестирования предпринять следующие шаги:

- кроссбраузерное тестирование лендинга
- тестирование на различных типах устройств
- показ посадочной страницы друзьям и семье («мама-тест»)
- интеграция инструментов аналитики в процесс теста
- подробное пошаговое рассмотрение гипотезы и плана тестирования

Этот комплексный метод работает быстрее и лучше, чем запуск А/А-тестов. Используйте триангуляцию (ниже мы подробнее разберем этот метод), пристально наблюдайте за происходящими процессами и продолжайте тестирование до достижения порога статистической значимости, чтобы минимизировать влияние инструментария, волатильности трафика и проблем несовместимости браузеров/устройств на результаты тестов.

Маркетологи редко задумываются над тем, что именно ошибки, связанные с волатильностью трафика и некорректным отображением идентичных посадочных страниц на различных типах устройств и в разных браузерах, являются самой распространенной причиной искажения результатов A/B-теста.

Методология проведения сплит-тестирования

### A/A/B/B — 25% распределение

A/A/B/B-тест — сегментирование входящего трафика на 4 выборки (25%): двум отдельным группам пользователей показывают в случайном порядке 2 варианта лендингов (A и B), что дает нам 4 возможные комбинации страниц — A/A, A/B, B/B, B/A.

Для чего это делается? Во-первых, для предварительной проверки настроек основного сплит-теста (как в классическом A/A-тестировании), во-вторых, для определения величины отклонений между полученными от разных групп средними результатами тестирования.

Другими словами, рекомбинация вариантов A/A, A/B, B/B, B/A позволяет маркетологу одновременно получать результаты обычного A/A-теста (когда обе группы видят одинаковый вариант, A или B) и классического A/B-теста (последовательность показа вариантов лендингов каждой группе соответствует отдельному полноценному сплит-тесту: например, A, A, B, B для первой группы).

Предположим, что вы убедились в валидности тестового инструментария, но разброс средних значений конверсии, полученных от разных групп, чрезмерно велик.

Что делать? — Успокоиться и принять как данность: главная ваша ошибка в том, что вы вычисляете среднее значение на основе очень маленькой статистической выборки.

Поясним на примере: представим, что трафик вашего лендинга/сайта — 20 посетителей. При использовании A/A/B/B-теста они сегментируются на 4 выборки по 5 человек в каждой. Что будет, если 5 из них являются постоянными посетителями и случайно оказались в одной статистической выборке? Исказит ли этот фактор результаты теста?

Разумеется, да.

Почему маркетологи используют этот метод? В основном потому, что он действительно работает в случае, если у вас небольшое количество конверсий — допустим, вы только начали тесты, или у вас специфическая маркетинговая ниша и ваш оффер таргетирован на крайне узкую целевую аудиторию.

Статистическое значение имеют результаты, полученные по достижении 350 конверсий на выборку при длительности теста минимум 2 недели, — так считает Крэйг Салливан.

Проблема с использованием этого метода заключается в том, что вы расщепляете трафик на лендинги А и В на 4 сегмента, так что «эффект перекоса» (effect of skew) проявляется сильнее, эффективный размер выборки меньше, а следовательно, показатель ошибок (error rate) для каждой отдельной выборки выше.

Проще говоря, шансы на то, что в данном случае вы получите заведомо искаженные данные, выше, чем в случае обычного А/В-теста. Также потому, что размеры выборок меньше, показатель ошибок будет выше для каждого проводимого измерения.

Если вы попробуете применить тестирование по схеме A/A/A/B/B/B, вы просто увеличите влияние «эффекта перекоса». Вообще, смысл всех этих предварительных приготовлений сводится не к определению того, как результаты тестов, полученные от идентичных выборок, отклоняются от среднего значения (такие отклонения называются флуктуацией) — речь идет о том, как флуктуация коррелирует с уровнем сегментации трафика (этот вопрос будет рассмотрен ниже).

Как оптимизировать конверсию при низком трафике?
### A/B/A — лучший способ

Этот метод имеет следующие преимущества: он позволяет выявить проблемы маркетингового инструментария (как обычный A/A) с меньшими затратами времени. Правда, у него есть тот же недостаток, что и у A/A/B/B-теста: 2 одинаковые выборки (A) будут получать пропорционально в 2 раза меньше трафика на каждую, следовательно, показатель ошибок для них будет выше.

И, разумеется, поскольку 2 выборки А будут небольшими, тестирование до достижения статистически значимых результатов займет больше времени, чем в случае обычного A/B-теста.

Тем не менее, перед нами — лучший способ валидации теста. Хотя без этой стадии подготовки к основному сплит-тестированию вполне можно обойтись.

### Почему маркетологи проводят А/А-тесты?

Иногда они делают это потому, что в кругах маркетологов A/A-тесты считаются чем-то вроде «визитной карточки» хорошего специалиста по оптимизации, залогом того, что основной тест будет проведен максимально тщательно и непредвзято.

A/A-тест также рассматривается как «генеральная репетиция» перед главным действием — это удобный способ запустить процесс с предварительной отладкой: понятно, что ремонт автомобиля «на ходу» обойдется гораздо дороже, чем его техническое обслуживание в гараже.

Однако в отличие от качественного предстартового техобслуживания A/A-тест не может удалить все дефекты, содержащиеся в гипотезе, сценарии и средствах практического сплит-тестирования. Возможно, что A/A-тест стоит использовать в случаях, когда вы проверяете какой-то сложный алгоритм основного тестирования, который вы намерены применять в дальнейшем. Но предварять каждый сплит-тест предварительным A/A-тестированием совсем не обязательно.

Дедукция как технология сплит-тестирования
### В чем заключаются проблемы А/А-тестирования?

Проблема прежде всего заключается в том, что вы тратите реальный платный трафик и драгоценное тестовое время на предварительную операцию (собственно A/A-тест), никак напрямую не способствующую ни оптимизации конверсии, ни росту доходов.

Если вы пытаетесь запустить 40 сплит-тестов в месяц, то у вас практически не будет возможности получать «живые данные», проанализировать их и внести необходимые коррективы в процесс тестирования — весь ваш трафик и время будут поглощены предварительным тестированием, которое должно длиться не менее 2–4 недель. А стоит ли оно того?

Другая проблема кроется в том, что почти 80% A/A-тестов в какой-то момент достигнут порога статистической значимости. Другими словами, тестовая система констатирует, что с высокой степенью достоверности оригинальный вариант лендинга лучше, чем оригинальный вариант лендинга. Почему? Потому что такова величина тестовой выборки, и потому что вы воспринимаете тест неправильно.

А если вы используете маленькую выборку, вы можете прийти к ложному умозаключению, что у вас что-то не в порядке — не хватает трафика, плохие инструменты аналитики и т. д., хотя это, возможно, далеко не так.

Еще одна проблема: когда вы проводите A/A-тестирование, вы сравниваете конверсионную производительность двух идентичных целевых страниц. Размер выборки и количество данных, что потребуются вам для того, чтобы убедиться в отсутствии значимого искажения результатов, будут огромными по сравнению с A/B-тестом.

Сколько людей нужно, чтобы при испытании «слепым методом» вкуса кока-колы (против той же кока-колы) прийти к выводу, что всем участникам теста этот напиток понравился одинаково? 500 человек? 50 000 человек? Миллион?

Именно поэтому опытные маркетологи никогда не проводят сплит-тесты с очень похожими целевыми страницами — обнаружить предельно мелкие преимущества одного варианта лендинга над другим очень трудно. В случае идентичной страницы эта задача становится практически невыполнимой: вы можете проводить A/-A тест на несколько недель дольше, чем непосредственно сам A/B-тест и не получить никакой ценной информации — либо потому, что «сломались» настройки теста, либо потому, что «сломалась» ваша способность понимать статистические выборки.

Хорошим примером маркетологов, не до конца понимающих что и зачем они делают, могут послужить те «эксперты», что упорно проводят затяжные A/A-тестирования, забывая о существовании других источников искажений результатов тестов: медленно преобразующихся пользователях (Slower Converter) и эффекте новизны (Novelty Effect).

Оптимизация конверсии и статистическая достоверность: что это значит?
Медленно преобразующиеся пользователи

Если вы будете проводить сплит-тест в течение 2 недель, а средний покупательский цикл составляет 4 недели, вы, останавливая тестирование, «вырежете» из учитываемой выборки некоторых пользователей, находящихся в конверсионной воронке, но не прошедших ее до конца. Подобное решение неизбежно приведет к искажению результатов теста.

Вот почему маркетологу важно знать длительность покупательского цикла — в A/B-тесте не должны принимать участие только быстро преобразующиеся пользователи, составляющие лишь некоторую часть от всей целевой аудитории оффера.

Маркетолог Тон Весселинг (Ton Wesseling) советует не останавливать тест, когда вы «закрываете» основную массу новых посетителей. Пусть те пользователи, что прошли только часть конверсионной воронки, видят, что эксперимент продолжается, и продолжают движение к ее финальному этапу. Это отличный способ провести участника через тестовую систему и увеличить статистическую выборку — а значит, и точность полученных результатов — без привлечения новых пользователей.

Эффект новизны

Уточнив длительность покупательского цикла, вы можете оптимизировать финальную фазу тестирования. А можно ли избежать искажений, возникающих на начальном этапе эксперимента? Да, но для этого следует устранить влияние так называемого «эффекта новизны».

Предположим, что первый участник тестирования посещает продающий лендинг в течение 4 недель (длительность покупательского цикла), при этом он все время видел старый вариант целевой страницы некоего уникального товарного предложения. Во время своего последнего визита он видит великолепную страницу, гораздо лучше нежели прежде раскрывающую преимущества данного оффера. Участник немедленно принимает решение о покупке — все, конверсионное действие совершено.

Второй участник, наблюдавший один и тот же вариант лендинга в течение тех же 4 недель, посещает страницу в очередной раз и по-прежнему видит старую (контрольную) версию страницы. По истечении 4 недель у обоих участников заканчивается их «жизненный цикл» в рамках проводимого сплит-теста, но один успел завершить конверсию, потому что увидел новый вариант лендинга, второй — нет.

Так эффект новизны искажает результаты теста. Теоретически, нежелательное влияние можно минимизировать, начав тест на несколько недель раньше и «маркируя» всех посетителей с помощью cookie — так вы отфильтруете для участия в эксперименте только новых пользователей, а не тех, кто может быть подвержен влиянию эффекта новизны в конце покупательского цикла. Желательно, чтобы участники сплит-тестирования находились на одном и том же этапе пользовательского цикла.

На результаты сплит-теста влияет множество искажающих факторов, и большинство из них с помощью A/A-теста выявить нельзя.

Эффект первичности в интернет-маркетинге
«Грязный секрет» тестирования

тестирования

Каждый бизнес имеет свои особенности, подвержен влиянию тенденций рынка, подчиняется определенным законам цикличности. Анализ результатов сплит-тестов, наблюдение за поведением целевой аудитории на лендингах и сайтах — лучшие способы научиться оптимизации маркетинговых стратегий, безусловно.

Но в практике тестирования есть одна «грязная тайна».

Вы получили 15% прирост конверсии в ходе сплит-тестов, проведенных в январе текущего года? Так вот — возможно, что таких результатов вы не добьетесь никогда больше!

Почему? Ну может случиться так, что вам сократят бюджет на PPC-маркетинг, значит, вы будете получать более «холодные» лиды. Возможно, вы дадите рекламу по ТВ, что оттолкнет от вашего бренда людей, высоко ценивших ваши прежние online-креативы.

Хотя подождите минуточку — все может работать гораздо лучше, чем вы думаете. Но вы этого не знаете. Это как знаменитый парадокс «кота Шрёдингера» (Schrödinger’s Cat): вы не знаете, покажет ли повторно проведенный сплит-тест тот же подъем конверсии.

В этом заключается проблема последовательного тестирования — вы должны двигаться дальше, не зная, сохранился ли прирост конверсии, зафиксированный в каком-либо из ранее проведенных сплит-тестов.

Не прекращайте тесты насовсем

Чтобы убедится в том, что в процессе сплит-тестирования был выбран лучший вариант лендинга, Крэйг Салливан оставляет законченные тесты, работающими «на холостом ходу» (5–10% от объема тестового трафика) на несколько недель после их «официального закрытия».

Если вы постоянно занимаетесь тестированием и оптимизацией, то это беспокойство о внесенных на лендинг изменениях носит скорее академический интерес, потому что главным подтверждением вашей правоты служит увеличение количества лидов и прирост прибыли — критерии чисто практические.

Проблема в том, что маркетологи тестируют какой-то элемент маркетинговой стратегии, оптимизируют его, а затем раз и навсегда забывают о нем. Однако у Крэйга есть лендинги, к которым он возвращается 4 года спустя после окончания сплит-теста и все еще находит резервы для оптимизации.

Не тратьте силы — сфокусируйтесь на «внушаемых» клиентах!
Триангуляция данных

Триангуляция данных

Напомним, что триангуляция есть «использование нескольких исследовательских методов как способ получения более достоверных эмпирических данных по сравнению с результатами, получаемыми при применении какого-либо одного метода в отдельности».

Проще говоря, маркетолог в ходе сплит-теста должен располагать по меньшей мере 2 пакетами инструментов метрики и анализа.

Это позволит вам иметь 2 массива данных для триангуляции или сверки результатов, полученных от разных источников, между собой. Если вы заметите резкую диспропорцию, то сможете устранить ее источник перед началом собственно сплит-теста.

Опытные маркетологи неоднократно сталкивались с расхождением данных, полученных от инструментов A/B-тестирования, с метрикой, выдаваемой аналитическими пакетами типа Google Analytics. Исходя из наличия данной проблемы, вы просто не можете доверять метрике, полученной из единственного источника — у вас в резерве должен быть альтернативный вариант данных для сравнения.

Не плачьте о потерянных данных, когда будет поздно — просто убедитесь, что вы застраховались от подобных неприятностей. К тому же наличие 2 пакетов инструментов метрики упрощает оперативную проверку данных, получаемых в ходе сплит-теста.

Смотрите на тест как шеф-повар

Маркетолог должен подходить к каждому тестированию как знаменитый повар к приготовлению трудоемкого «коронного блюда»: он должен постоянно искать, дегустировать, пробовать и перепроверять свой сплит-тест от начала и до конца.

Вот что по этому поводу говорит Салливан:

«Главное, что я получил от внимательного наблюдения за тысячами тестирований — теперь я интуитивно чувствую, что происходит и что может пойти не так. Иногда я могу проверять тест сотню раз в неделю без видимой причины, просто потому что разброс результатов выглядит подозрительным для меня.

Сопротивляйтесь искушению нарисовать красивый график в начале тестов и подгонять получаемые данные под него!

Если тест идет меньше одного бизнес-цикла (покупательский цикл), например, неделю — игнорируйте результаты. Если у вас меньше 350 завершенных конверсий на выборку — не говоря уж о 250 — игнорируйте результаты. Если получаемые данные пока что сильно отличаются друг от друга — игнорируйте результаты.

Ваше “блюдо” еще не готово.».

Сегментация

Любой опытный маркетолог знает, что метрика, получаемая от лендинга, с течением времени заметно меняется: допустим, что на веб-ресурс приходят случайные посетители, увидевшие вашу новую рекламу; это изменение трафика с неким временным лагом влияет на точность и характер данных, получаемых вами.

Большая проблема с результатами сплит-тестов кроется в том, что маркетолог получает некие средние значения, не обращая внимания на то, что скрыто внутри «среднего» — отдельные сегменты трафика.

Используя инструменты аналитики (тот же Google Analytics), вы можете настроить максимальную производительность тестирования для каждого сегмента. Но тут требуется большая осторожность: чем больше у вас сегментов, тем меньше размер статистической выборки, соответствующей каждому из них. Не делите трафик на совсем уж крошечные сегменты или по крайней мере не доверяйте слепо данным, полученным при низком количестве завершенных конверсий или от крайне малочисленной группы пользователей.

Сегментация может дать вам очень полезную информацию о релевантности A/B-тестирования, потому что она базируется на известных атрибутах посетителей — демографические характеристики, история посещений и т. д., — а не на абстрактных и неточных цифровых данных. Если вы запускаете неудачный сплит-тест, не приведший к приросту конверсии, вы тем не менее можете увидеть, как различные группы (сегменты) пользователей отреагировали на вашу гипотезу тестирования, а это сама по себе очень ценная информация.

Сегментация клиентской базы как инструмент повышения эффективности бизнеса
Вместо заключения

Будущее сплит-тестирования принадлежит все более точной персонализации тестов, все более тонкой сегментации трафика — но, разумеется, без фанатизма! ;)

Получению точных результатов тестов способствует не только упомянутая выше сегментация, но и триангуляция — применение более чем одного пакета инструментов метрики и аналитики. Никто, разумеется, не отменяет, «человеческий фактор» — персональный опыт маркетолога, проведшего достаточно большое количество тестирований.

Есть ли польза от A/A- и A/A/B/B-тестов? Возможно, что мы что-то упускаем из виду, но скорее всего, эти тесты попросту бесполезны. Пока что сколько-нибудь убедительных конкурентов у доброго старого A/B-теста нет.



https://www.unisender.com/ru/blog/sovety/kak-zapustit-aa-test/#:~:text=%D0%90%2F%D0%90%2D%D1%82%D0%B5%D1%81%D1%82%20%E2%80%94%20%D1%8D%D1%82%D0%BE,%D1%87%D1%82%D0%BE%2D%D1%82%D0%BE%20%D0%BF%D0%BE%D1%88%D0%BB%D0%BE%20%D0%BD%D0%B5%20%D1%82%D0%B0%D0%BA.

https://yagla.ru/blog/analitika/chto-takoe-aa-testirovanie-i-kak-ego-provesti/

https://ux-journal.ru/aa-testing-in-experimentation.html

https://www.flocktory.com/blog/a-a-testy-chto-eto-i-kak-ikh-provodit

https://habr.com/ru/articles/323702/

https://habr.com/ru/companies/poborchy/articles/299142/

https://koch-kir.medium.com/%D0%BD%D0%B5-%D1%81%D1%82%D0%BE%D0%B8%D1%82-%D0%BF%D1%80%D0%BE%D0%B2%D0%BE%D0%B4%D0%B8%D1%82%D1%8C-%D0%B0-%D0%B0-%D0%B2-%D1%82%D0%B5%D1%81%D1%82-936e9e7a3b96

