_Kafka_ - это брокер сообщений.

Что такое брокер сообщений?

_Брокер сообщений_ - это система, которая помогает разным частям программного обеспечения обмениваться данными. Если упростить, то _брокер сообщений_ передает данные между разными программами.

Основные функции брокера сообщений

_Передача сообщений_ - брокер сообщений принимает данные от одной программы (продюсера) и передает их другой программе (консьюмеру). Это позволяет разным частям системы работать независимо друг от друга.

_Буферизация_ - брокер сообщений может временно хранить данные, если консьюмер не готов их принять. Это помогает избежать потерь данных и обеспечивает надежность системы.

_Маршрутизация_ - брокер сообщений может направлять данные к нужным консьюмерам на основе различных правил. Это позволяет гибко управлять потоками данных.

_Гарантия доставки_ - брокер сообщений может обеспечивать гарантию доставки сообщений, что особенно важно для критически важных данных.

Где можно использовать брокер сообщений?

_Микросервисная архитектура_ - в микросервисной архитектуре разные сервисы могут обмениваться данными через брокер сообщений. Это позволяет сервисам работать независимо друг от друга и легко масштабироваться.

_Интернет вещей (Internet of Things - IoT)_ - в системах IoT данные с датчиков могут отправляться в брокер сообщений, который затем передает их на серверы для обработки и анализа.

_Финансовые системы_ - в финансовых системах брокер сообщений может использоваться для передачи транзакций между различными подсистемами, такими как системы учета и системы отчетности.

Преимущества использования брокера сообщений

_Разделение задач_ - разные части системы могут работать независимо друг от друга, что упрощает разработку и поддержку системы.

_Надежность_ - брокер сообщений обеспечивает надежную передачу данных, что особенно важно для критически важных систем.

_Масштабируемость_ - брокер сообщений может обрабатывать большие объемы данных и легко масштабироваться для увеличения производительности.

_Гибкость_ - брокер сообщений позволяет гибко управлять потоками данных, что делает систему более адаптивной к изменениям.

Причины появления брокеров и их необходимость

Брокеры сообщений появились в ответ на несколько ключевых проблем и потребностей, с которыми сталкивались разработчики и архитекторы программного обеспечения. Вот основные причины их появления:

1. Разделение задач и модульность

_Проблема_ - в монолитных системах разные части программного обеспечения часто тесно связаны друг с другом, что затрудняет их разработку, тестирование и поддержку.

_Решение_ - брокеры сообщений позволяют разделить систему на независимые модули, которые могут обмениваться данными через брокер. Это упрощает разработку и поддержку, так как каждый модуль может разрабатываться и тестироваться отдельно.

2. Надежность и отказоустойчивость

_Проблема_ - в традиционных системах потеря связи между компонентами может привести к потере данных или сбою системы.

_Решение_ - брокеры сообщений обеспечивают буферизацию и гарантию доставки сообщений. Это означает, что даже если один из компонентов системы временно недоступен, данные не теряются и будут доставлены, когда компонент станет доступен снова.

3. Масштабируемость

_Проблема_ - с ростом объема данных и увеличением числа пользователей традиционные системы могут сталкиваться с проблемами производительности.

_Решение_ - брокеры сообщений легко масштабируются горизонтально, что позволяет обрабатывать большие объемы данных и поддерживать высокую производительность. Это особенно важно для систем, работающих в реальном времени.

4. Гибкость и адаптивность

_Проблема_ - в статических системах изменение одного компонента может потребовать изменения всей системы.

_Решение_ - брокеры сообщений позволяют гибко управлять потоками данных и легко добавлять новые компоненты или изменять существующие без необходимости изменять всю систему.

5. Асинхронная обработка

_Проблема_ - в синхронных системах один компонент должен ждать ответа от другого компонента, что может замедлять выполнение задач.

_Решение_ - брокеры сообщений поддерживают асинхронную обработку, что позволяет компонентам системы работать независимо друг от друга и не ждать ответов. Это ускоряет выполнение задач и повышает общую производительность системы.

6. Управление сложностью

_Проблема_ - с ростом системы управление сложностью становится все более затруднительным.

_Решение_ - брокеры сообщений помогают управлять сложностью, предоставляя централизованный механизм для обмена данными между компонентами системы. Это упрощает архитектуру и облегчает управление системой.

Примеры использования брокеров сообщений

_Микросервисная архитектура_ - в микросервисных системах брокеры сообщений используются для обмена данными между микросервисами, что позволяет им работать независимо друг от друга.

_Интернет вещей_ - в системах IoT брокеры сообщений используются для передачи данных с датчиков на серверы для обработки и анализа.

_Финансовые системы_ - в финансовых системах брокеры сообщений используются для передачи транзакций между различными подсистемами, такими как системы учета и системы отчетности.

Брокеры сообщений появились в ответ на потребность в более гибких, надежных и масштабируемых системах - пресловутый переход от монолита к микросервисам, когда возникает потребность в "общении" микросервисов между собой. Они помогают разделить задачи, управлять сложностью, обеспечивать надежность и отказоустойчивость, а также поддерживать высокую производительность систем.

_Kafka_ – это  современная технология, разработанная компанией _LinkedIn_ в 2011 году и существенно улучшенная _Apache Software Foundation_. Она представляет собой надежный, масштабируемый и устойчивый инструмент для обработки и передачи данных в режиме реального времени, иначе говоря, _шину данных_. Основная задача _шины данных_ – передача информации из системы-источника в целевую систему. При одном продюсере и одном консьюмере все просто – кажется, что шина не нужна. Но что, если существует 10 консьюмеров и 5 продюсеров, и их число может расти? Тогда придется реализовать 50 интеграций, каждая из которых потребует протоколов взаимодействия, форматов данных и схем валидации. Помимо этого, необходимо учитывать такие нефункциональные требования, как:

- надежность и гарантия доставки;

- подключение новых сервисов;

- интеграция различных технологий.

Задача усложняется, но _Kafka_ способна справиться с ней лучше других инструментов. _Apache Kafka_ имеет несколько ключевых отличий от традиционных баз данных, таких как _MySQL_ или _PostgreSQL_, поскольку она была спроектирована для шардированной и отказоустойчивой потоковой обработки большого объема данных в реальном времени. _Apache Kafka_ обеспечивает надежную передачу данных, поддерживая при этом высокие нагрузки. Она состоит из нескольких компонентов:

_Producer (производитель)_ - приложение, генерирующее данные и отправляющее их в _Kafka_.

_Broker (брокер)_ - сервер _Kafka_, который хранит и управляет потоками данных. В новой архитектуре _KRaft_ брокеры также могут выполнять функции контроллера, управляя метаданными кластера без необходимости использования _ZooKeeper_.

_Topic (тема)_ - категория, в которой данные публикуются производителями. Темы разделяются на разделы _(partitions - партиции)_, что позволяет масштабировать обработку данных.

_Consumer (потребитель)_ - приложение, которое читает данные из _Kafka_ и обрабатывает их. Потребители могут объединяться в группы для совместного потребления данных из тем.

_Контроллер (Controller)_ - в новой архитектуре _KRaft_ контроллер реализован внутри _Kafka-брокеров_ и управляет метаданными кластера, координируя работу без использования _ZooKeeper_.

_ZooKeeper (устаревший компонент)_ - ранее использовался для координации и управления брокерами _Kafka_, а также для хранения метаданных о состоянии кластера. В новой архитектуре _KRaft_ его использование больше не требуется.

Ключевые особенности:

_Ориентация на потоковую обработку данных_ - в отличие от традиционных баз данных, которые ориентированы на хранение структурированных данных, _Kafka_ создана для обработки непрерывных потоков данных в реальном времени.

_Сохранение данных как событий_ - _Kafka_ не поддерживает полнотекстовый поиск или выполнение сложных запросов на месте. Вместо этого она сохраняет события и данные в топиках для последующей обработки.

_Сообщения вместо записей_ - в _Kafka_ данные организованы в виде сообщений, а не записей, как в реляционных базах данных. Эти сообщения могут содержать как структурированные, так и неструктурированные данные.

_Доставка сообщений_ - одним из ключевых отличий _Kafka_ является доставка и сохранение порядка сообщений, что важно для приложений, требующих надежности и согласованности данных.

_Отказоустойчивость и масштабируемость_ - _Kafka_ разработана с учетом горизонтального масштабирования, что позволяет добавлять новые брокеры и партиции для обработки большого объема данных, обеспечивая репликацию и отказоустойчивость более естественным образом, чем в классических СУБД. Новые версии _Kafka_ изначально включают механизмы репликации данных и управления аварийным переключением брокеров.

Что касается применения, то технология особенно эффективна для следующих технических задач:

- Агрегация событий и логов - например, обработка данных о кликах. Если необходимо отделить данные от ботов от данных от реальных пользователей, такие очищенные данные затем могут использоваться в системах машинного обучения, аналитики, отчетности и визуализации.

- _IoT-приложения_ для сенсоров - создание приложения для мониторинга данных от _IoT-устройств_, таких как сенсоры в зданиях или на производстве. Сенсоры могут передавать данные через _Kafka-as-a-Service_, а ваше приложение будет их анализировать и реагировать на них.

- Доставка событий нескольким потребителям - когда событие генерируется в одном месте и обрабатывается сразу несколькими системами без необходимости добавления дополнительной логики обработки на уровне приложения.

- Система уведомлений и событий - использование _Kafka_ для отправки уведомлений о событиях, таких как новые заказы или обновления статусов. Клиенты могут подписаться на определенные темы и получать сообщения в реальном времени. Это полезно для интеграции с _CRM/ERP_ системами.

- Обработка больших объемов данных - благодаря архитектуре _Kafka_, которая использует партиционирование и распределение данных между брокерами, можно горизонтально масштабировать систему для обработки растущего потока данных. Библиотеки, такие как _Kafka Streams_ и _Apache Flink_, могут помочь в обработке данных в реальном времени.

- Платформа для совместной работы и обсуждений - приложение для обмена сообщениями и обсуждения проектов и задач. _Kafka_ может обеспечить мгновенную доставку сообщений и создание персонализированных потоков обсуждений.

- _Stream-processing_ и _CDC_ - использование _Kafka_ в качестве промежуточного хранилища для переноса данных между системами.

- Проектирование системы на основе событий - _Apache Kafka_ идеально подходит для создания приложений с использованием архитектуры, основанной на событиях.

_Kafka_ предоставляет надежную и масштабируемую платформу для передачи, хранения и обработки следующих событий:

- В _Kafka_ хранятся основные события системы, а микросервисы обновляют локальные базы данных.

- Решение используется как источник истины, обеспечивая отказоустойчивость и надежность.

- _Kafka_ использует партиционирование для разделения данных, что позволяет обрабатывать события параллельно и распределять нагрузку.

- _Kafka_ позволяет анализировать данные в реальном времени для мгновенной реакции на события, обнаружения аномалий и создания персонализированных рекомендаций.

Чтобы понять, как работает _Kafka_, необходимо рассмотреть её основные компоненты. В последнее время _Kafka_ претерпела важные изменения, включая возможность работы без _ZooKeeper_ благодаря новому механизму управления метаданными - _KRaft_. Ниже рассмотрены основные компоненты _Kafka_ в контексте этих изменений.

1. Producer (Производитель)

_Producer_ - это приложение или сервис, который генерирует данные и отправляет их в _Kafka_ для последующей обработки. Данные отправляются в определенные _topics (темы)_, которые являются логическими контейнерами для сообщений.

```
from kafka import KafkaProducer

# Конфигурация Producer
producer = KafkaProducer(bootstrap_servers='localhost:9092')

# Отправка сообщения в Kafka
producer.send('my_topic', b'Hello from Kafka!')

# Завершение операции
producer.flush()
```

В этом примере:

_bootstrap_servers_ - адрес брокера _Kafka_.

_send_ - метод для отправки сообщений в указанную тему _(my_topic)_. Сообщение должно быть в байтовом формате, поэтому используется явное указание _b'Hello, Kafka!'_.

_flush_ - ожидание отправки всех сообщений перед завершением работы.

2. Broker (Брокер)

_Брокер_ - это сервер _Kafka_, который хранит данные и управляет их обработкой. Брокер - это серверная часть _Kafka_, которую нужно запускать и настраивать отдельно.

3. Topic (Тема)

_Topic_ - это логическое имя, которое используется для категории сообщений. Тему можно создать с помощью утилиты командной строки _Kafka_.

В общем виде выглядит так:

```
kafka-topics.sh --create --topic <topic_name> --bootstrap-server <broker_address> --partitions <num_partitions> --replication-factor <num_replicas>
```

Какие параметры использует:

_kafka-topics.sh_ - это утилита командной строки, которая используется для управления темами в _Kafka_. Позволяет создавать, удалять и изменять темы, а также получать информацию о них.

_--create_ - флаг, который указывает утилите, что нужно создать новую тему.

_--topic <topic_name>_ - параметр _--topic_ задает имя темы, которую необходимо создать.

_--bootstrap-server <broker_address>_ - параметр _--bootstrap-server_ указывает адрес одного или нескольких брокеров _Kafka_, к которым утилита должна подключиться для выполнения команды. Адрес указывается в формате _host:port_.

_--partitions <num_partitions>_ - параметр _--partitions_ определяет количество разделов _(partitions)_ для темы. _Разделы_ - это логические части темы, которые распределяют данные. Каждый раздел может находиться на одном или нескольких брокерах. Разделение на разделы позволяет масштабировать потребление и управление данными.

_--replication-factor <num_replicas>_ - параметр _--replication-factor_ определяет, сколько копий каждого раздела будет храниться на разных брокерах. Репликация обеспечивает отказоустойчивость. Если один брокер выйдет из строя, данные все равно будут доступны благодаря копиям, хранящимся на других брокерах. Если необходимо создать тему для тестов или небольшой нагрузки, один раздел и одна реплика могут быть достаточны. Для продакшн-среды обычно создают больше разделов и используют репликацию для повышения производительности и отказоустойчивости.

4. Consumer (Потребитель)

_Consumer_ - это приложение, которое читает сообщения из _Kafka_.

```
from kafka import KafkaConsumer

# Конфигурация Consumer
consumer = KafkaConsumer(
    'my_topic',
    bootstrap_servers='localhost:9092',
    auto_offset_reset='earliest',  # Начать чтение с самого начала
    group_id='my_group'            # Группа потребителей
)

# Чтение сообщений из Kafka
for message in consumer:
    print(f"Received message: {message.value.decode('utf-8')}")

```
В примере выше:

_auto_offset_reset='earliest'_ - начинать чтение с самого первого сообщения, если нет сохраненного смещения.

_group_id_ - группа потребителей, что позволяет нескольким клиентам совместно потреблять данные.

5. Контроллер (Controller) и KRaft

С переходом на _KRaft_, контроллер стал неотъемлемой частью архитектуры _Kafka_. В этом режиме контроллер реализован внутри брокеров, используя алгоритм _Raft_ для управления метаданными и координации кластера. Теперь _Kafka_ может функционировать без использования _ZooKeeper_, что значительно упрощает инфраструктуру.

Основные функции контроллера в _KRaft_:

- Управление метаданными кластера.

- Координация и управление лидерами разделов.

- Обеспечение согласованности данных через алгоритм _Raft_.

6. ZooKeeper (Устаревший компонент)
ZooKeeper ранее использовался для координации и управления брокерами Kafka, а также для хранения метаданных о состоянии кластера. В новых версиях Kafka (начиная с версии 2.8) ZooKeeper может больше не использоваться, если вы выбрали режим KRaft. В предыдущих версиях Kafka (до 2.8) ZooKeeper использовался в качестве контроллера. Он выполнял роль базы для хранения метаданных о состоянии узлов кластера и расположении сообщений, позволял организовать репликацию, отказоустойчивость и шардирование.



Когда не стоит использовать Apache Kafka: случаи, когда использование излишне
Apache Kafka — мощная и широко используемая платформа для обработки потоков данных в реальном времени, которая подходит для множества сценариев. Однако, как и любая технология, Kafka не является универсальным решением, и есть случаи, когда ее использование может быть нецелесообразным или даже излишним. В этой статье мы рассмотрим такие сценарии и объясним, почему в определенных ситуациях стоит рассмотреть альтернативы.

1. Малые объемы данных и низкая нагрузка
Kafka создана для работы с огромными объемами данных и высокой нагрузкой, особенно в распределенных системах. Если ваш проект оперирует небольшим количеством данных или имеет минимальную нагрузку, использование Kafka может быть излишним и усложняет инфраструктуру. В таких случаях могут подойти более простые решения, такие как:

RabbitMQ или ActiveMQ: Подходят для менее масштабируемых систем с меньшей нагрузкой.
Простые очереди сообщений: Например, Amazon SQS или Google Cloud Pub/Sub.
2. Требование низкой задержки
Kafka обеспечивает высокую пропускную способность, но задержка доставки сообщений может быть выше по сравнению с другими системами, особенно в случаях, когда требуется подтверждение записи и соблюдение строгих гарантий доставки. Если ваше приложение критично к задержке (например, требует мгновенной реакции на события), могут подойти следующие варианты:

Redis Streams: Подходит для систем с низкими задержками, обеспечивает быструю обработку данных.
ZeroMQ: Легковесная и быстрая библиотека для обмена сообщениями.
3. Отсутствие требований к устойчивости и репликации
Kafka известна своей устойчивостью и механизмами репликации, которые обеспечивают высокую надежность данных. Однако эти функции могут быть избыточными, если ваше приложение не требует таких гарантий или если потеря данных в определенных сценариях не критична. В таких случаях можно использовать более легкие системы, которые проще в управлении и эксплуатации:

Redis Pub/Sub: Хорошо подходит для случаев, когда не требуется долговременное хранение сообщений и высокая надежность.
Прямой обмен через HTTP/WebSockets: Подходит для простых приложений, где достаточно прямой передачи данных между сервисами.
4. Ограниченный бюджет и ресурсы
Развертывание и управление Kafka-кластером требует значительных ресурсов, как аппаратных, так и человеческих. Если ваш проект ограничен в бюджете или у вас нет достаточных ресурсов для поддержки масштабируемой инфраструктуры, стоит рассмотреть альтернативы:

Облачные сервисы: Многие облачные провайдеры предлагают управляемые сервисы, такие как AWS Kinesis, которые могут оказаться более экономичными и простыми в управлении.
Менее сложные очереди сообщений: RabbitMQ или Amazon SQS могут обеспечить нужный функционал без необходимости в сложной инфраструктуре.
5. Простая обработка данных или ETL
Если вам нужно просто преобразовать, загрузить и обработать данные в базе данных (ETL), использование Kafka может быть излишне сложным. В таких случаях подойдут специализированные инструменты для обработки данных:

Apache NiFi: Простой в использовании инструмент для маршрутизации и трансформации данных.
Airflow: Подходит для сложных ETL процессов, где требуется управление зависимостями и расписанием задач.
6. Редкие или нерегулярные данные
Если данные поступают редко или в незначительных объемах, Kafka может оказаться излишней. Системы, предназначенные для работы с низкой частотой сообщений, могут быть более эффективными:

Cron задачи или расписания: Если данные собираются в определенные временные интервалы, использование простой задачи по расписанию может быть достаточным.
REST API: Если данные поступают по требованию, использование REST API может быть проще и эффективнее.
7. Необходимость простого хранения событий
Если ваша задача заключается в простом хранении и доступе к событиям, Kafka может оказаться сложным и избыточным решением. Подходящие альтернативы:

Реляционные базы данных: Подойдут для простого хранения и доступа к структурированным данным.
NoSQL базы данных: Например, MongoDB, которые позволяют гибко хранить и обрабатывать большие объемы данных.
 
Apache Kafka — мощный инструмент для работы с потоками данных, но его использование оправдано далеко не всегда. Если ваш проект требует простоты, экономии ресурсов или если объем данных и нагрузка на систему невелики, стоит рассмотреть другие решения, которые лучше соответствуют вашим требованиям.

Прежде чем внедрять Kafka, оцените ваши потребности в обработке данных, требования к надежности, масштабу, задержке и бюджету. В ряде случаев более простые и специализированные инструменты могут предложить лучшее соотношение функциональности и сложности.

Специфичность инструмента еще раз подчеркивает наличие шага с таким названием. Очень хотелось в примерах нарисовать картинки с сервисом PUSH - уведомлений в воображаемой соц.сети - но это одновременно было бы хорошим примером использования Kafka, а также стереотипизировало бы Ваше восприятие Kafka в целом. Как Вы видите кейсы применения весьма и весьма интересные и не тривиальные.


